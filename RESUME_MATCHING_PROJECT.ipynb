{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqzF6s7l72yc"
      },
      "outputs": [],
      "source": [
        "# cleaning part 1\n",
        "\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "ds = load_dataset(\"facehuggerapoorv/resume-jd-match\")\n",
        "\n",
        "jd_list = []\n",
        "resume_list = []\n",
        "label_list = []\n",
        "\n",
        "separator = \">> the resume: <<\"\n",
        "prefix_to_remove = \"For the given job description \"\n",
        "\n",
        "for example in ds['train']:\n",
        "    text = example['text']\n",
        "    label = example['label']\n",
        "\n",
        "    if separator in text:\n",
        "        jd_part, resume_part = text.split(separator, 1)\n",
        "\n",
        "\n",
        "        jd_cleaned = jd_part.replace(prefix_to_remove, \"\").strip(\"<>\").strip()\n",
        "        resume_cleaned = resume_part.strip(\"<>\").strip()\n",
        "    else:\n",
        "        jd_cleaned = \"\"\n",
        "        resume_cleaned = \"\"\n",
        "\n",
        "    jd_list.append(jd_cleaned)\n",
        "    resume_list.append(resume_cleaned)\n",
        "    label_list.append(label)\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'jd': jd_list,\n",
        "    'resume': resume_list,\n",
        "    'label': label_list\n",
        "})\n",
        "\n",
        "df.to_csv('jd_resume_cleaned.csv', index=False)\n",
        "\n",
        "print(\"Saved to 'jd_resume_cleaned.csv' with cleaned JD text.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nlp preprocessing -- 2\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "import re\n",
        "\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "df = pd.read_csv('/content/jd_resume_cleaned.csv')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 2 and not token.is_punct]\n",
        "\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "df['processed_jd'] = df['jd'].apply(preprocess_text)\n",
        "df['processed_resume'] = df['resume'].apply(preprocess_text)\n",
        "\n",
        "print(df[['jd', 'processed_jd', 'resume', 'processed_resume', 'label']].head())\n",
        "\n",
        "df.to_csv('jd_resume_cleaned_preprocessed.csv', index=False)\n",
        "\n",
        "print(\" Preprocessing complete! Cleaned file saved as 'jd_resume_cleaned_preprocessed.csv'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "INOB9uBb8Fpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Classifiers without tuning --- 3\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv('/content/jd_resume_cleaned_preprocessed.csv')\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=3000)\n",
        "X = tfidf.fit_transform(df['processed_resume'])\n",
        "y = df['label_encoded']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'SVM - Linear': SVC(kernel='linear', probability=True),\n",
        "    'SVM - RBF': SVC(kernel='rbf', probability=True),\n",
        "    'SVM - Poly': SVC(kernel='poly', degree=3, probability=True),\n",
        "    'Bagging (Logistic Regression)': BaggingClassifier(estimator=LogisticRegression(max_iter=1000), n_estimators=10, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
        "    'LightGBM': lgb.LGBMClassifier(random_state=42),\n",
        "    'CatBoost': CatBoostClassifier(verbose=0, random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n Training: {model_name}\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    y_pred_labels = le.inverse_transform(y_pred)\n",
        "    y_true_labels = le.inverse_transform(y_test)\n",
        "\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_true_labels, y_pred_labels),\n",
        "        'Precision': precision_score(y_true_labels, y_pred_labels, average='weighted', zero_division=0),\n",
        "        'Recall': recall_score(y_true_labels, y_pred_labels, average='weighted'),\n",
        "        'F1-Score': f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\n Final Comparison Table:\")\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "RFE-IlN68Z6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Classifiers with tuning --- 4\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.base import clone\n",
        "from scipy.stats import uniform, randint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/jd_resume_cleaned_preprocessed.csv')\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=3000)\n",
        "X = tfidf.fit_transform(df['processed_resume'])\n",
        "y = df['label_encoded']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'SVM - Linear': SVC(kernel='linear', probability=True),\n",
        "    'SVM - RBF': SVC(kernel='rbf', probability=True),\n",
        "    'SVM - Poly': SVC(kernel='poly', degree=3, probability=True),\n",
        "    'Bagging (Logistic Regression)': BaggingClassifier(estimator=LogisticRegression(max_iter=1000), n_estimators=10, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
        "    'LightGBM': lgb.LGBMClassifier(random_state=42),\n",
        "    'CatBoost': CatBoostClassifier(verbose=0, random_state=42)\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'Logistic Regression': {\n",
        "        'C': uniform(0.01, 10),\n",
        "        'penalty': ['l2']\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'alpha': uniform(0.0, 1.0)\n",
        "    },\n",
        "    'SVM - Linear': {\n",
        "        'C': uniform(0.1, 10),\n",
        "        'kernel': ['linear']\n",
        "    },\n",
        "    'SVM - RBF': {\n",
        "        'C': uniform(0.1, 10),\n",
        "        'gamma': ['scale', 'auto'],\n",
        "        'kernel': ['rbf']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': randint(50, 200),\n",
        "        'max_depth': [None, 10, 20, 30],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': randint(50, 150),\n",
        "        'max_depth': randint(3, 10),\n",
        "        'learning_rate': uniform(0.01, 0.3)\n",
        "    },\n",
        "    'LightGBM': {\n",
        "        'n_estimators': randint(50, 150),\n",
        "        'num_leaves': randint(20, 100),\n",
        "        'learning_rate': uniform(0.01, 0.3)\n",
        "    },\n",
        "    'CatBoost': {\n",
        "        'iterations': randint(50, 150),\n",
        "        'depth': randint(3, 10),\n",
        "        'learning_rate': uniform(0.01, 0.3)\n",
        "    }\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n Tuning and Training: {model_name}\")\n",
        "    if model_name in param_grids:\n",
        "        param_dist = param_grids[model_name]\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=clone(model),\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            cv=3,\n",
        "            scoring='accuracy',\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        search.fit(X_train, y_train)\n",
        "        best_model = search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        best_model = model\n",
        "\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    y_pred_labels = le.inverse_transform(y_pred)\n",
        "    y_true_labels = le.inverse_transform(y_test)\n",
        "\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_true_labels, y_pred_labels),\n",
        "        'Precision': precision_score(y_true_labels, y_pred_labels, average='weighted', zero_division=0),\n",
        "        'Recall': recall_score(y_true_labels, y_pred_labels, average='weighted'),\n",
        "        'F1-Score': f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\n Final Comparison Table After Tuning:\")\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "nkCIUknw8qDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------DL-------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rZw6HpR29QbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n",
        "pip install tensorflow numpy pandas scikit-learn"
      ],
      "metadata": {
        "id": "ynzdAlTh9V70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "ds = load_dataset(\"facehuggerapoorv/resume-jd-match\")\n",
        "\n",
        "jd_list = []\n",
        "resume_list = []\n",
        "label_list = []\n",
        "\n",
        "separator = \">> the resume: <<\"\n",
        "prefix_to_remove = \"For the given job description \"\n",
        "\n",
        "for example in ds['train']:\n",
        "    text = example['text']\n",
        "    label = example['label']\n",
        "\n",
        "    if separator in text:\n",
        "        jd_part, resume_part = text.split(separator, 1)\n",
        "\n",
        "        jd_cleaned = jd_part.replace(prefix_to_remove, \"\").strip(\"<>\").strip()\n",
        "        resume_cleaned = resume_part.strip(\"<>\").strip()\n",
        "    else:\n",
        "        jd_cleaned = \"\"\n",
        "        resume_cleaned = \"\"\n",
        "\n",
        "    jd_list.append(jd_cleaned)\n",
        "    resume_list.append(resume_cleaned)\n",
        "    label_list.append(label)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'jd': jd_list,\n",
        "    'resume': resume_list,\n",
        "    'label': label_list\n",
        "})\n",
        "\n",
        "df.to_csv('jd_resume_cleaned.csv', index=False)\n",
        "\n",
        "print(\"Saved to 'jd_resume_cleaned.csv' with cleaned JD text.\")\n"
      ],
      "metadata": {
        "id": "7TQxJRCC9g9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "AMVKQ6D19llH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    text = re.sub(r'^(professional summary|summary|overview)[\\s:]*', '', text.strip(), flags=re.IGNORECASE)\n",
        "    return text\n",
        "df['resume'] = df['resume'].apply(clean_text)\n",
        "df['jd'] = df['jd'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "IbMzw-ai9nbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "label_map = {'Good Fit': 0, 'No Fit': 1, 'Potential Fit': 2}\n",
        "df['label'] = df['label'].map(label_map)\n",
        "\n",
        "print(\"NaNs in df['label']:\", df['label'].isnull().any())\n",
        "df = df.dropna(subset=['label'])\n",
        "\n",
        "X_resume = df['resume'].values\n",
        "X_jd = df['jd'].values\n",
        "y = df['label'].values\n",
        "\n",
        "X_resume_train, X_resume_val, X_jd_train, X_jd_val, y_train, y_val = train_test_split(\n",
        "    X_resume, X_jd, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "nzL_aLwD9ptW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(\"NaNs in y_train:\", np.any(pd.isnull(y_train)))\n",
        "print(\"Unique labels:\", np.unique(y_train))\n",
        "print(\"unique labels \", np.unique(df['label']))"
      ],
      "metadata": {
        "id": "y1BCdnt69rxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizaion and padding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "vocab_size = 20000\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(list(X_resume) + list(X_jd))\n",
        "\n",
        "\n",
        "X_resume_seq_train = tokenizer.texts_to_sequences(X_resume_train)\n",
        "X_jd_seq_train = tokenizer.texts_to_sequences(X_jd_train)\n",
        "X_resume_seq_val = tokenizer.texts_to_sequences(X_resume_val)\n",
        "X_jd_seq_val = tokenizer.texts_to_sequences(X_jd_val)\n",
        "\n",
        "\n",
        "maxlen = 512\n",
        "X_resume_pad_train = pad_sequences(X_resume_seq_train, maxlen=maxlen, padding='post')\n",
        "X_jd_pad_train = pad_sequences(X_jd_seq_train, maxlen=maxlen, padding='post')\n",
        "X_resume_pad_val = pad_sequences(X_resume_seq_val, maxlen=maxlen, padding='post')\n",
        "X_jd_pad_val = pad_sequences(X_jd_seq_val, maxlen=maxlen, padding='post')\n"
      ],
      "metadata": {
        "id": "79APAFFa9tIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "embedding_index = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = vectors\n",
        "\n",
        "print(f\"Found {len(embedding_index)} word vectors.\")\n"
      ],
      "metadata": {
        "id": "5H1AGot09uok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= vocab_size:\n",
        "        continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "IiFDMhmm9v_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "=\n",
        "resume_input = Input(shape=(maxlen,), name='Resume_Input')\n",
        "jd_input = Input(shape=(maxlen,), name='JD_Input')\n",
        "\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=maxlen,\n",
        "    trainable=False\n",
        ")\n",
        "\n",
        "resume_embedded = embedding_layer(resume_input)\n",
        "jd_embedded = embedding_layer(jd_input)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# %% Model 0: LSTM\n",
        "resume_lstm = LSTM(64)(resume_embed)\n",
        "jd_lstm = LSTM(64)(jd_embed)\n",
        "\n",
        "x4 = Concatenate()([resume_lstm, jd_lstm])\n",
        "x4 = BatchNormalization()(x4)\n",
        "x4 = Dense(128, activation='relu')(x4)\n",
        "x4 = Dropout(0.4)(x4)\n",
        "x4 = Dense(64, activation='relu')(x4)\n",
        "x4 = Dropout(0.3)(x4)\n",
        "output4 = Dense(3, activation='softmax')(x4)\n",
        "\n",
        "model_lstm = Model(inputs=[resume_input, jd_input], outputs=output4)\n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# %% Model 1: BiLSTM\n",
        "resume_bilstm = Bidirectional(LSTM(64))(resume_embed)\n",
        "jd_bilstm = Bidirectional(LSTM(64))(jd_embed)\n",
        "\n",
        "x1 = Concatenate()([resume_bilstm, jd_bilstm])\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "x1 = Dropout(0.4)(x1)\n",
        "x1 = Dense(64, activation='relu')(x1)\n",
        "x1 = Dropout(0.3)(x1)\n",
        "output1 = Dense(3, activation='softmax')(x1)\n",
        "\n",
        "model_bilstm = Model(inputs=[resume_input, jd_input], outputs=output1)\n",
        "model_bilstm.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
        "\n",
        "# %% Model 2: BiGRU\n",
        "resume_bigru = Bidirectional(GRU(64))(resume_embed)\n",
        "jd_bigru = Bidirectional(GRU(64))(jd_embed)\n",
        "\n",
        "x2 = Concatenate()([resume_bigru, jd_bigru])\n",
        "x2 = BatchNormalization()(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "x2 = Dropout(0.4)(x2)\n",
        "x2 = Dense(64, activation='relu')(x2)\n",
        "x2 = Dropout(0.3)(x2)\n",
        "output2 = Dense(3, activation='softmax')(x2)\n",
        "\n",
        "model_bigru = Model(inputs=[resume_input, jd_input], outputs=output2)\n",
        "model_bigru.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
        "\n",
        "# %% Model 3: Hybrid BiLSTM + BiGRU\n",
        "resume_bilstm_h = Bidirectional(LSTM(64))(resume_embed)\n",
        "jd_bigru_h = Bidirectional(GRU(64))(jd_embed)\n",
        "\n",
        "x3 = Concatenate()([resume_bilstm_h, jd_bigru_h])\n",
        "x3 = BatchNormalization()(x3)\n",
        "x3 = Dense(128, activation='relu')(x3)\n",
        "x3 = Dropout(0.4)(x3)\n",
        "x3 = Dense(64, activation='relu')(x3)\n",
        "x3 = Dropout(0.3)(x3)\n",
        "output3 = Dense(3, activation='softmax')(x3)\n",
        "\n",
        "model_hybrid = Model(inputs=[resume_input, jd_input], outputs=output3)\n",
        "model_hybrid.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])\n",
        "\n",
        "# %% Train All Models\n",
        "print(\"\\nTraining LSTM Model\")\n",
        "history_lstm = model_lstm.fit(\n",
        "    [X_resume_pad_train, X_jd_pad_train], y_train,\n",
        "    validation_data=([X_resume_pad_val, X_jd_pad_val], y_val),\n",
        "    epochs=10, batch_size=32, callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "print(\"\\nTraining BiLSTM Model\")\n",
        "history_bilstm = model_bilstm.fit(\n",
        "    [X_resume_pad_train, X_jd_pad_train], y_train,\n",
        "    validation_data=([X_resume_pad_val, X_jd_pad_val], y_val),\n",
        "    epochs=10, batch_size=32, callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "print(\"\\nTraining BiGRU Model\")\n",
        "history_bigru = model_bigru.fit(\n",
        "    [X_resume_pad_train, X_jd_pad_train], y_train,\n",
        "    validation_data=([X_resume_pad_val, X_jd_pad_val], y_val),\n",
        "    epochs=10, batch_size=32, callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "print(\"\\nTraining Hybrid Model\")\n",
        "history_hybrid = model_hybrid.fit(\n",
        "    [X_resume_pad_train, X_jd_pad_train], y_train,\n",
        "    validation_data=([X_resume_pad_val, X_jd_pad_val], y_val),\n",
        "    epochs=10, batch_size=32, callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# %% Evaluate All Models\n",
        "def evaluate(model, name):\n",
        "    print(f\"\\n--- Evaluation for {name} ---\")\n",
        "    y_pred = model.predict([X_resume_pad_val, X_jd_pad_val])\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "    print(classification_report(y_val, y_pred_class, target_names=['Good Fit', 'No Fit', 'Potential Fit']))\n",
        "    print(confusion_matrix(y_val, y_pred_class))\n",
        "\n",
        "evaluate(model_lstm, \"LSTM\")\n",
        "evaluate(model_bilstm, \"BiLSTM\")\n",
        "evaluate(model_bigru, \"BiGRU\")\n",
        "evaluate(model_hybrid, \"Hybrid BiLSTM+GRU\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QnwBTS_X9znW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPER PARAMETER TUNING ON BILSTM\n",
        "\n",
        "def build_lstm_model(hp):\n",
        "    lstm_units = hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
        "    dense_units = hp.Int('dense_units', min_value=64, max_value=256, step=64)\n",
        "    dropout_rate1 = hp.Float('dropout1', 0.3, 0.4, step=0.1)\n",
        "    dropout_rate2 = hp.Float('dropout2', 0.3, 0.4, step=0.1)\n",
        "    learning_rate = hp.Choice('learning_rate', [1e-3, 1e-4])\n",
        "\n",
        "    resume_bilstm = Bidirectional(LSTM(lstm_units))(resume_embed)\n",
        "    jd_bilstm = Bidirectional(LSTM(lstm_units))(jd_embed)\n",
        "\n",
        "    x = Concatenate()([resume_bilstm, jd_bilstm])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(dense_units, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate1)(x)\n",
        "    x = Dense(dense_units // 2, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate2)(x)\n",
        "    output = Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[resume_input, jd_input], outputs=output)\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer=Adam(learning_rate),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_lstm_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='kt_dir',\n",
        "    project_name='bilstm_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    [X_resume_pad_train, X_jd_pad_train], y_train,\n",
        "    validation_data=([X_resume_pad_val, X_jd_pad_val], y_val),\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "for param in best_hps.values:\n",
        "    print(f\"{param}: {best_hps.get(param)}\")\n",
        "\n",
        "model_bilstm = tuner.hypermodel.build(best_hps)\n",
        "history = model_bilstm.fit(\n",
        "    [X_resume_pad_train, X_jd_pad_train], y_train,\n",
        "    validation_data=([X_resume_pad_val, X_jd_pad_val], y_val),\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "def evaluate(model, name):\n",
        "    print(f\"\\n--- Evaluation for {name} ---\")\n",
        "    y_pred = model.predict([X_resume_pad_val, X_jd_pad_val])\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "    print(classification_report(y_val, y_pred_class, target_names=['Good Fit', 'No Fit', 'Potential Fit']))\n",
        "    print(confusion_matrix(y_val, y_pred_class))\n",
        "\n",
        "evaluate(model_bilstm, \"Tuned BiLSTM\")"
      ],
      "metadata": {
        "id": "1yKuLA7B_uk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# ------------------------------------------------------------------------ATS SCORE CALCULATION-------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "QVu-lj4sACUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/jd_resume_cleaned_preprocessed.csv')\n",
        "\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "jd_texts = df['processed_jd'].tolist()\n",
        "resume_texts = df['processed_resume'].tolist()\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "tfidf_vectorizer.fit(jd_texts + resume_texts)\n",
        "\n",
        "jd_tfidf = tfidf_vectorizer.transform(jd_texts)\n",
        "resume_tfidf = tfidf_vectorizer.transform(resume_texts)\n",
        "\n",
        "similarity_scores = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    sim = cosine_similarity(jd_tfidf[i], resume_tfidf[i])[0][0]\n",
        "    similarity_scores.append(sim)\n",
        "\n",
        "df['similarity_score'] = similarity_scores\n",
        "\n",
        "print(df[['jd', 'resume', 'similarity_score']].head())\n",
        "\n",
        "df.to_csv('jd_resume_with_similarity.csv', index=False)\n",
        "\n",
        "print(\" Cosine similarity applied successfully! File saved as 'jd_resume_with_similarity.csv'\")\n"
      ],
      "metadata": {
        "id": "Dtowq-_eAHFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using llm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "df = pd.read_csv(\"jd_resume_cleaned.csv\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def preprocess(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^A-Za-z\\s]\", \" \", text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in stop_words and len(t) > 1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"processed_jd\"] = df[\"jd\"].apply(preprocess)\n",
        "df[\"processed_resume\"] = df[\"resume\"].apply(preprocess)\n",
        "\n",
        "model_names = [\n",
        "    \"all-mpnet-base-v2\",\n",
        "    \"paraphrase-MiniLM-L6-v2\",\n",
        "    \"all-MiniLM-L12-v1\",\n",
        "    \"all-roberta-large-v1\",\n",
        "    \"bert-base-nli-mean-tokens\"\n",
        "]\n",
        "\n",
        "similarity_data = {\"label\": df[\"label\"]}\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"\\nðŸ” Encoding with {model_name}...\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    jd_embeddings = model.encode(df[\"processed_jd\"].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
        "    resume_embeddings = model.encode(df[\"processed_resume\"].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
        "\n",
        "    sim_scores = util.cos_sim(jd_embeddings, resume_embeddings).diagonal().cpu().numpy()\n",
        "    similarity_data[f\"{model_name}_score\"] = sim_scores\n",
        "\n",
        "result_df = pd.DataFrame(similarity_data)\n",
        "\n",
        "summary_stats = result_df.groupby(\"label\").agg([\"count\", \"mean\", \"median\", \"std\", \"min\", \"max\"])\n",
        "\n",
        "result_df.to_csv(\"ats_similarity_scores_all_models.csv\", index=False)\n",
        "summary_stats.to_csv(\"ats_similarity_stats_by_label.csv\")\n",
        "\n",
        "print(\"\\nðŸ“Š Similarity Score Summary Stats by Fit Label:\")\n",
        "print(summary_stats)"
      ],
      "metadata": {
        "id": "34j-kPe5AOQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UI\n",
        "# stream lit final code\n",
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Configure Gemini API\n",
        "genai.configure(api_key=\"AIzaSyAw_eSjW1d9Z5u8RWZ_GJ8OEU_oDoUfmgE\")\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n",
        "\n",
        "# Utility Functions\n",
        "def clean_json_block(text):\n",
        "    match = re.search(r\"(?:json)?\\s*(.*?)\\s*\", text, re.DOTALL)\n",
        "    if not match:\n",
        "        raise ValueError(\"No valid JSON block found in Gemini response.\")\n",
        "    return match.group(1).strip()\n",
        "\n",
        "def extract_keywords(jd_text):\n",
        "    prompt = f\"\"\"\n",
        "    Extract the most important hard and soft skills, tools, and technologies from the following job description.\n",
        "    Return the result as a JSON list of keywords (e.g., [\"Python\", \"Machine Learning\", \"Communication\"]).\n",
        "\n",
        "    JD:\n",
        "    {jd_text}\n",
        "\n",
        "    Wrap the list in triple backticks so it is easy to parse.\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    text = response.text.strip()\n",
        "    return json.loads(clean_json_block(text))\n",
        "\n",
        "def generate_variations(keywords):\n",
        "    prompt = f\"\"\"\n",
        "    Given the following list of keywords, return a JSON dictionary where each keyword maps to 3-5 variations or synonyms.\n",
        "    Example format: {{ \"Python\": [\"Python 3\", \"Python programming\", \"Scripting\"], ... }}\n",
        "\n",
        "    Keywords: {keywords}\n",
        "\n",
        "    Wrap the dictionary in triple backticks.\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    text = response.text.strip()\n",
        "    return json.loads(clean_json_block(text))\n",
        "\n",
        "def calculate_ats_score(resume, variations_dict):\n",
        "    resume = resume.lower()\n",
        "    matched = 0\n",
        "    total = 0\n",
        "    missing_keywords = []\n",
        "\n",
        "    for keyword, variations in variations_dict.items():\n",
        "        all_terms = [keyword.lower()] + [v.lower() for v in variations]\n",
        "        found = any(re.search(r'\\b' + re.escape(term) + r'\\b', resume) for term in all_terms)\n",
        "        if found:\n",
        "            matched += 1\n",
        "        else:\n",
        "            missing_keywords.append(keyword)\n",
        "        total += 1\n",
        "\n",
        "    score = round((matched / total) * 100, 2) if total else 0\n",
        "    return score, missing_keywords\n",
        "\n",
        "def safe_gemini_call(func, *args, retries=3, delay=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            result = func(*args)\n",
        "            time.sleep(delay + random.uniform(0.5, 1.5))\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e):\n",
        "                time.sleep(delay * (attempt + 1))\n",
        "            else:\n",
        "                raise\n",
        "    raise RuntimeError(f\"Failed after {retries} retries: {func._name_}\")\n",
        "\n",
        "def extract_text_from_pdf(uploaded_pdf):\n",
        "    with fitz.open(stream=uploaded_pdf.read(), filetype=\"pdf\") as doc:\n",
        "        text = \"\"\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# ---------------------- Streamlit UI ----------------------\n",
        "\n",
        "st.set_page_config(page_title=\"ATS Score Checker\", layout=\"centered\")\n",
        "st.title(\" Resume vs JD ATS Score Checker\")\n",
        "st.markdown(\"Upload a *resume (PDF)* and a *job description (TXT)* to check your ATS match score.\")\n",
        "\n",
        "resume_file = st.file_uploader(\" Upload Resume (PDF only)\", type=[\"pdf\"])\n",
        "jd_file = st.file_uploader(\"Upload Job Description (TXT only)\", type=[\"txt\"])\n",
        "\n",
        "if st.button(\"Calculate ATS Score\") and resume_file and jd_file:\n",
        "    try:\n",
        "        resume_text = extract_text_from_pdf(resume_file)\n",
        "        jd_text = jd_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "        with st.spinner(\"Extracting keywords and scoring...\"):\n",
        "            keywords = safe_gemini_call(extract_keywords, jd_text)\n",
        "            variations = safe_gemini_call(generate_variations, keywords)\n",
        "            score, missing_keywords = calculate_ats_score(resume_text, variations)\n",
        "\n",
        "\n",
        "        st.success(f\" ATS Score: *{score}%*\")\n",
        "        if score >= 70:\n",
        "            st.markdown(\" *Great match!* Your resume aligns well with the JD.\")\n",
        "        elif score >= 50:\n",
        "            st.markdown(\"*Moderate match.* Consider tweaking your resume to better align with the JD.\")\n",
        "        else:\n",
        "            st.markdown(\" *Low match.* Improve your resume by including more relevant skills or keywords.\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\" Extracted Keywords from JD\")\n",
        "        cols = st.columns(3)\n",
        "        for i, keyword in enumerate(keywords):\n",
        "            with cols[i % 3]:\n",
        "                st.markdown(f\" *{keyword}*\")\n",
        "\n",
        "        # ----- Keyword Variations -----\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\" Keyword Variations / Synonyms\")\n",
        "        for keyword, vars in variations.items():\n",
        "            st.markdown(f\"ðŸ”¹ *{keyword}*: {', '.join(vars)}\")\n",
        "\n",
        "        # ----- Missing Keywords -----\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\" Missing Keywords (Consider adding to your resume)\")\n",
        "        if missing_keywords:\n",
        "            missing_cols = st.columns(3)\n",
        "            for i, keyword in enumerate(missing_keywords):\n",
        "                with missing_cols[i % 3]:\n",
        "                    st.markdown(f\" *{keyword}*\")\n",
        "        else:\n",
        "            st.success(\" All JD keywords are present in your resume!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"An error occurred: {e}\")\n",
        "else:\n",
        "    st.info(\"Please upload both *Resume (PDF)* and *JD (TXT)* to calculate the score.\")"
      ],
      "metadata": {
        "id": "ZRzIFkaLAZ09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}